[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Introduction\nHello world!\nThis Learning Diary is part of the CASA0023 module, Remotely Sensing Cities and Environments, which I’m taking as part of the MSc Urban Spatial Science at UCL. Here, you’ll find weekly entries summarizing key takeaways from each lecture, examples of practical applications, and my personal reflections.\nBut first, let me introduce myself!\nMy name is Fiorella, and I’m currently pursuing an MSc in Urban Spatial Science. Back in 2021, I graduated as an architect and urbanist in Peru. Since then, I have developed a strong interest in sustainability, climate change, water resources, and urban settlements, particularly how these factors affect urban and natural environments. As an example, during my undergraduate thesis, I focused on assessing changes in a river in the Peruvian Amazon, accelerated by climate change, and proposed solutions to the urban challenges that emerged from these changes.\nSince graduating, I have worked in the public sector, contributing to Lima’s Rimac River renaturalization project. This role involved urban analysis, master planning, urban design, and policy implementation, with a strong emphasis on risk prevention, and nature-based solutions.\nWhile I have some basic experience using Earth Observation (EO) and remote sensing to address topics like those mentioned above, my approach has been largely empirical. That’s why I find this module to be an exciting opportunity to deepen my knowledge of these tools and processes, enabling me to better inform policies and urban solutions in future projects or research.\nI am particularly interested in how these technologies can be applied to urban challenges in the Global South, where they are often underutilized due to knowledge gaps. That’s why, throughout this diary, my reflections will aim to connect these tools to my background and interests, as well as explore their real-world applications in contexts similar to my country’s.\nAnd if you are curious about my previous projects, here you can have a glimpse at them!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome</span>"
    ]
  },
  {
    "objectID": "W1_Introduction.html",
    "href": "W1_Introduction.html",
    "title": "2  An Introduction to Remote Sensing",
    "section": "",
    "text": "2.1 Summary\nThis week’s lecture covered the basics of Earth Observation (EO) and Remote Sensing including topics such as definitions, relevance and terminology of Earth Observation, as well as more technical concepts to describe sensors (resolutions, types, interactions of light). In this summary, I’ll focus on the latter, mainly defining some of the key characteristics of sensors (Image 1). To have a clearer understanding of these concepts, I will exemplify them with information from two of the main satellites discussed in class: Landsat and Sentinel (Image 2).\nImage 1: Mind map of main characteristics of sensors\nImage 2: Mind map comparing main characteristics of two of the main sensors: Landsat and Sentinel\nFrom this comparison, it’s worth noticing that overall, Sentinel shows better characteristics, like spatial resolutions with more detail, more spectral bands and more frequent temporal resolution than Landsat. It would be interesting to see in which cases, despite having seemingly lower characteristics, Landsat imagery could represent a better tool to assess an spatial problem.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W2_Portfolio.html",
    "href": "W2_Portfolio.html",
    "title": "3  Portfolio tools: Xaringan and Quarto",
    "section": "",
    "text": "This week we explored how tools like Xaringan and Quarto can be used to have reproducible presentations and documents, useful for data science projects. As an exercise, I have developed this book using Quarto and a presentation on the Sentinel -2 satellite using Xaringan, which you can see here:\n\n\n\n\n\n\n\n\nAs a reflection on this exercise, I found that learning how to use these tools, specially Xaringan, was quite challenging, and probably not the best option for a simple presentation, but could be really useful when used to display code or data through tables for example, or when using some of the interactive tools that XaringanExtra has.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Portfolio tools: Xaringan and Quarto</span>"
    ]
  },
  {
    "objectID": "W1_Introduction.html#summary",
    "href": "W1_Introduction.html#summary",
    "title": "2  An Introduction to Remote Sensing",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week’s lecture focused on the foundations of Earth Observation (EO) and Remote Sensing. From all the contents of the class, I will focus, on this summary, on the differences between two main sensors: Landsat and Sentinel. This comparison will draw on some of the contents of the lecture, like types of sensors, resolutions, spectral bands, and applications.\n*Pending to upload mind map",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W1_Introduction.html#applications",
    "href": "W1_Introduction.html#applications",
    "title": "2  An Introduction to Remote Sensing",
    "section": "2.2 Applications",
    "text": "2.2 Applications\nSince this week’s summary included a comparison between Landsat and Sentinel sensors, I considered relevant to read a paper that compares both satellites’ imagery applied to analyse Burn Severity Mapping in Western North America. This paper by Howe et al (2022) analysed 26 fires in western North America, and found that “Sentinel generally performed as well or better than Landsat for four spectral indices of burn severity”, also that Sentinel’s finer spatial resolution helps to identify fine-scale fire effects and therefore has a more precise identification of spatial patterns of fires and burned areas.\nOn the other hand, the paper “Analysis of urban heat islands with Landsat satellite images and GIS in Kuala Lumpur Metropolitan City” (Kasniza et al., 2023) explored the evolution of heat islands and their relationship to land surface temperature in Kuala Lumpur using Landsat 8 imagery. Instead of focusing on the research details, I want to focus on the methodology, where they explained that Landsat 8 was chosen because it provides thermal data through Band 10: Thermal Infrared (which isn’t available on Sentinel). This band was used alongside other bands like NDVI and NIR for the analysis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W1_Introduction.html#reflections",
    "href": "W1_Introduction.html#reflections",
    "title": "2  An Introduction to Remote Sensing",
    "section": "2.3 Reflections",
    "text": "2.3 Reflections\nAfter reviewing the main concepts of sensors and comparing Landsat and Sentinel satellites, it seemed that Sentinel has more advantages in terms of its various resolutions and some uses like burn mapping. However, after reviewing literature and considering the pros and cons of each, it’s worth pointing out that Landsat is still highly relevant, especially to certain topics, for example when it comes to analyzing heat, thanks to its thermal bands. Also, since Sentinel is relatively new, if I were looking to analyze long-term trends, Landsat would probably be the best option, which is something to keep in mind for future projects. In general, the main reflection from this, would be that depending of the research we want to do, it’s worth assessing which sensor would give us greater information, and looking for examples in previous research is a great tool for that.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W3_RemoteSensingData.html",
    "href": "W3_RemoteSensingData.html",
    "title": "4  Remote Sensing Data",
    "section": "",
    "text": "4.1 Summary\nThis week introduced a lot of new concepts related to corrections, data joining, and enhancements in remote sensing. To keep things clear for future reference, I organized them into categories and decided to do kind of a “dictionary” of these concepts, so it will be useful to understand them when reviewing literature and seeing applications of it.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Sensing Data</span>"
    ]
  },
  {
    "objectID": "W3_RemoteSensingData.html#applications",
    "href": "W3_RemoteSensingData.html#applications",
    "title": "4  Remote Sensing Data",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nThese corrections and enhancements are essential for making sure remote sensing data is accurate and actually useful. For example, atmospheric corrections are super important for environmental monitoring, where we need consistent multi-temporal comparisons. Geometric corrections are crucial for historical imagery alignment, especially in change detection studies. Radiometric calibration ensures that sensor data is comparable across time and space.\nEnhancements also have a ton of applications in urban studies, agriculture, and disaster response. Band ratios (like NDVI) help in assessing vegetation health, while texture analysis is great for land-use classification. PCA is often used for detecting land-cover changes, highlighting major differences in multi-temporal images. Image fusion techniques improve spatial resolution, making high-precision mapping and infrastructure monitoring more effective.\nOne interesting example is multi-sensor fusion, where high-resolution panchromatic images enhance low-resolution multispectral data to improve feature detection. A study titled Multi-Sensor Fusion: A Simulation Approach to Pansharpening Aerial and Satellite Images (MDPI, 2020) discusses different ways to sharpen images and extract better features using fusion techniques.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Sensing Data</span>"
    ]
  },
  {
    "objectID": "W3_RemoteSensingData.html#reflections",
    "href": "W3_RemoteSensingData.html#reflections",
    "title": "4  Remote Sensing Data",
    "section": "4.3 Reflections",
    "text": "4.3 Reflections\nAt first, learning about corrections and enhancements felt unnecessary as most modern datasets come preprocessed anyway. But after seeing the applications I think its worth knowing the possibilities we have and what we could do if we ever encounter raw data(maybe not even satellite data). Even if we end up using only Analysis-ready data, I now think it’s important to know what kind of process it has been through so we can assess it better and know what we are working with. Even though I now realise its importance, I found this week to be a bit overwhelming because of all the concepts, but after organizing everything, it started making sense. Some papers are still hard to follow with all their complex formulas, but at least now I have a better foundation to understand what’s going on, so I guess we are having progress!\nA couple things catched my attention this week. One thing that surprised me was how much regression is used in remote sensing. I always thought of regression as something for statistical modeling (like in CASA007), but it’s actually everywhere here, aligning images, calibrating radiance, enhancing quality, etc. The other one was seeing Andy’s fieldwork for atmospheric correction which seems pretty cool. It made me think that sometimes we might need higher levels of precision for our images and its interesting to see all the options we have available to handle that.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Sensing Data</span>"
    ]
  },
  {
    "objectID": "W4_Policy.html",
    "href": "W4_Policy.html",
    "title": "5  An Introduction to Remote Sensing",
    "section": "",
    "text": "5.1 Summary\nThe Plan Integral de Reconstrucción con Cambios (PIRCC) is a strategy developed by the peruvian government to rebuild and strengthen areas affected by El Niño Costero. Its goal is not just to repair damaged infrastructure but also to make communities more resilient against future disasters. The plan promotes sustainable urban development and better risk management, recognizing that prevention is more effective than post-disaster reconstruction. Also, given the increasing impact of climate change, the PIRCC highlights the need to prepare for extreme weather events rather than just reacting to them.\nThat said, while the plan includes prevention measures, these have mostly focused on building flood defenses, dikes, and urban development plans for affected cities, but is missing a set of tools to better inform the location of these projects from a data-driven approach, and that overall, allow long-term risk monitoring, including tools that could provide real-time data and analysis to guide urban planning and infrastructure decisions. Without that, rebuilding efforts might not be too strategic, and could have less accuracy, reducing that way its effectiveness to prevent future natural phenomena.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W4_Policy.html#applications",
    "href": "W4_Policy.html#applications",
    "title": "5  An Introduction to Remote Sensing",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nConsidering this, and in order to assist with contributing to PIRCC’s policies goals, I consider it would be relevant to create a monitoring tool using Landsat imagery(because of its long-term data) that can analyse previous years’ affected areas by El Niño and with that information classify land risk. These data can be used to identify regions with repeated flooding, land degradation, and other vulnerability factors that are indicative of high-risk areas.\nFor that, spectral indices such as NDVI (Normalized Difference Vegetation Index) and NDBI (Normalized Difference Built-up Index) could be used to assess land cover changes and urban expansion, helping to identify areas where improvements are most needed.\nWith this application, we could shift towards a more data-driven approach to disaster prevention that could be replicated in different areas affected by this phenomenon, and ultimately, helps better inform policies to maximize its effects.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W4_Policy.html#reflections",
    "href": "W4_Policy.html#reflections",
    "title": "5  An Introduction to Remote Sensing",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nThrough this brief, I could understand how to link what we are learning on Earth Observation, to planning urban development, which is related to my background as an urban planner. Also, having a critical analysis of the policy, it made me realize that they are lacking some important data that could improve its effectiveness.\nThrough the application, I consider satellite imagery can be leveraged to address specific challenges posed by El Niño, and can better anticipate future risks, making the PIRCC more effective and sustainable in the long term.\nAdditionally, through this exercise, I’ve recognized the importance of collaboration between different data sources, such as satellite imagery and ground-level assessments, to create a comprehensive view of the situation. Also, it’s clear that while remote sensing can provide invaluable insights, it must be combined with local knowledge and community engagement to ensure that the data is used effectively in shaping policies and practices on the ground.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W6_GEE.html",
    "href": "W6_GEE.html",
    "title": "6  Google Earth Engine",
    "section": "",
    "text": "6.1 Summary\nThis week, we finally started using Google Earth Engine (GEE), and honestly, it felt like a game changer compared to earlier tools like SNAP. GEE makes satellite image analysis way more practical and less time-consuming. We went through the basics: how to access and manipulate satellite imagery, filter and scale values, join images, clip them, and even perform Principal Component Analysis (PCA).\nOne thing to mention is that GEE runs on JavaScript, which sounds intimidating at first, but so far, we’ve only used relatively simple commands, so it’s not that bad. I have summarized some of the main things to remember when using Javascript in GEE, in the following image:\nAlso, some words to keep in mind when working in GEE have been summarized here:\nA key takeaway is that using GEE’s built-in server side functions is way better performance wise. So, for example, instead of writing traditional loops, we should use functions like .map() to speed things up as they have been optimized for GEE.\nOther important concepts:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "W6_GEE.html#applications",
    "href": "W6_GEE.html#applications",
    "title": "6  Google Earth Engine",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nGEE’s massive satellite data catalog opens the door for a huge range of applications. We can do everything from climate studies to nighttime light analysis, with global coverage for most datasets. This is especially valuable for regions in the Global South, where detailed geospatial datasets are often lacking. With GEE, we can bypass that limitation and still conduct meaningful research and analysis.\nSome key application areas:\n\nEnvironmental Monitoring: Analyzing land cover changes, deforestation, and water body dynamics.\nUrban Studies: Monitoring urban expansion, heat islands, and transportation networks.\nAgriculture & Vegetation: Using NDVI and other indices to assess crop health and vegetation patterns.\nDisaster Response: Mapping flood-prone areas, tracking wildfires, and assessing damage after natural disasters.\nAir Quality & Climate: Analyzing pollution patterns and long-term climate trends.\n\nThere’s also the possibility of integrating GEE with machine learning models for tasks like land classification and object detection. And on top of all that, GEE even allows us to build interactive web applications, definitely something I am looking to try as I am also taking the CASA25 module.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "W6_GEE.html#reflections",
    "href": "W6_GEE.html#reflections",
    "title": "6  Google Earth Engine",
    "section": "6.3 Reflections",
    "text": "6.3 Reflections\nSwitching to GEE made everything feel much more efficient. Compared to previous weeks, loading and manipulating large datasets (even for the whole world) was a breeze. The user interface of GEE was a bit overwhelming at first, but that’s probably just because it was my first time using it, but overall it seems that it offers many functionalities that I am looking forward to try in the next weeks. On that line, the GEE catalog made me realize how much data we have available and how using Remote Sensing is democratizing the access to many datasets that will definitely benefit research and data-informed policy making especially in countries where data availability is usually an issue, like my country. I think the possibilities are endless now!\nOn another topic, when Ollie mentioned that even though GEE has been around for over a decade, Google could decide to shut it down at any time, it made me think that it would be such a huge loss especially after seeing how much research has been done since it was launched, but it also made me think that then it makes sense that we didn’t go straight to it(even though that’s what I was initially expecting) but instead we first focused on learning the theoretical concepts and understanding the logic behind what’s happening in the background. I think this way, even if in the future we have to change to another program, we will not be starting from scratch as we now know the foundations of it.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "W8_Classification2.html",
    "href": "W8_Classification2.html",
    "title": "8  An Introduction to Remote Sensing",
    "section": "",
    "text": "8.1 Summary",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W8_Classification2.html#applications",
    "href": "W8_Classification2.html#applications",
    "title": "8  An Introduction to Remote Sensing",
    "section": "8.2 Applications",
    "text": "8.2 Applications",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W8_Classification2.html#reflections",
    "href": "W8_Classification2.html#reflections",
    "title": "8  An Introduction to Remote Sensing",
    "section": "8.3 Reflections",
    "text": "8.3 Reflections",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W7_Classification.html",
    "href": "W7_Classification.html",
    "title": "7  An Introduction to Remote Sensing",
    "section": "",
    "text": "7.1 Summary\nWeek 7 notes, yet to be organized:\nExpert learning: use human knowledge to train models\nMachine learning: teach computers to razonate like humans\nClassification: assign categories or discrete values\nRegression trees: continous dependent variables. Used when linear regression doesn’t fit (if it doesn’t have the 4 linear regression conditions)\nRandom forests: use many decision trees\nISODATA: same as k-means but with more hyperparameters\nSupervised learning:\nSpatial autocorrelation: if the train and test data are too close, they are probably very similar and the accuracy could be too high but the model not robust enough (overfitting)\nOverfitting:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W7_Classification.html#applications",
    "href": "W7_Classification.html#applications",
    "title": "7  An Introduction to Remote Sensing",
    "section": "7.2 Applications",
    "text": "7.2 Applications",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W7_Classification.html#reflections",
    "href": "W7_Classification.html#reflections",
    "title": "7  An Introduction to Remote Sensing",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nThis week was mind blowing. I am not taking the CASA06 module so I haven’t had the opportunity to see all the Machine Learning and classification options and I think this week was a great introduction/summary of most of the available options.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W9_SAR.html",
    "href": "W9_SAR.html",
    "title": "9  An Introduction to Remote Sensing",
    "section": "",
    "text": "9.1 Summary\nWEEK 9 Notes, yet to be organized:\nC band is the most useful SAR band. Long enough that is not noisy\nSAR is seeing at 45° intead of having a huge antenaa(which means higher resolution), it receives images as moving, gaining distance and resolution\nscattering mechanism: the way that objects reflect\nrough scattering: chaotic, Sentinel 1 VV band\nwe only have access to VH and VV\nX band is very easy to scatter, it just bounces and generates a rough surface C band penetrates leaves and shows branchs, generates volumes L band and P band can penetrate through branches and generate double bounde\nVV is good for surface roughness\n2 MODIS: Terra and Aqua",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W9_SAR.html#applications",
    "href": "W9_SAR.html#applications",
    "title": "9  An Introduction to Remote Sensing",
    "section": "9.2 Applications",
    "text": "9.2 Applications",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W9_SAR.html#reflections",
    "href": "W9_SAR.html#reflections",
    "title": "9  An Introduction to Remote Sensing",
    "section": "9.3 Reflections",
    "text": "9.3 Reflections",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>An Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "W6_GEE.html#summary",
    "href": "W6_GEE.html#summary",
    "title": "6  Google Earth Engine",
    "section": "",
    "text": "GEE Elements\nMeaning\n\n\n\n\nImage\nRaster\n\n\nFeature\nVector\n\n\nImageCollection\nA stack of images\n\n\nFeatureCollection\nA stack of features\n\n\nClient side\nFront end: The part that users interact with\n\n\nServer side\nBack end: Where the data is retrieved and processed\n\n\n\n\n\n\nScale & Resolution: GEE aggregates data based on zoom level—so the further you zoom out, the bigger each pixel represents. Scale and resolution are always linked!\nProjection: Everything is converted to the Mercator projection by default.\nFiltering: To avoid loading excessive data, we always filter by time and spatial bounds.\nOperations & Applications: GEE lets us perform geometric operations, corrections, enhancements, and even advanced tasks like machine learning, classification, and deep learning.\n\n\n6.1.1 Practical\nIn the practical, we applied these concepts to the city of Delhi, but I also decided to analyze a Peruvian city following the same steps. It was interesting to apply the techniques in a familiar context, though I encountered limitations, such as needing to increase the cloud presence threshold to obtain enough images. But overall it was amazing to finally use GEE and see how fast and practical it was to load the data for anywhere in the world and run the analysis.\nImage 1: PCA analysis of Iquitos, Peru",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "W3_RemoteSensingData.html#summary",
    "href": "W3_RemoteSensingData.html#summary",
    "title": "4  Remote Sensing Data",
    "section": "",
    "text": "4.1.0.1 Key Terms:\n\nIrradiance: Radiation reaching Earth from the Sun\nRadiance: Radiation leaving Earth toward the satellite\nReflectance: The proportion of incoming radiation reflected by a surface\nSurface Reflectance: Reflectance at the bottom of the atmosphere (after atmospheric correction).\nAnalysis-ready data: Preprocessed images, usually in Surface Reflectance format (so we don’t have to do all the corrections ourselves!)\n\n\n\n\n4.1.0.2 Corrections:\n\nGeometric correction: Aligns misaligned images using control points and regression (basically shifting everything so it matches properly). Useful for correcting historical maps to match modern spatial data.\nAtmospheric correction: Removes distortions caused by atmospheric scattering (because the atmosphere its always there!).\nMethods include:\n\nDark Object Subtraction (DOS): Finds something that should have zero reflectance and subtracts its measured value from all pixels\nPseudo-Invariant Features (PIFs): Uses objects with stable reflectance over time as references for correction (great for long-term studies)\nFlat correction: Uses field-measured values (without atmospheric interference) as a baseline for regression\n\nOrthorectification: Fixes distortions from sensor tilt\nRadiometric calibration: Converts Digital Number (DN) to spectral radiance to standardize measurements\n\n\n\n4.1.0.3 Enhancements:\n\nContrast adjustments: Modifies image appearance without changing data values (basically, just making it look better)\nBand ratios: Dividing one band by another (e.g., NDVI for vegetation analysis)\nFiltering: Can be low-pass (smoothing) or high-pass (highlighting edges, like for detecting buildings)\nPrincipal Component Analysis (PCA): Reduces dimensionality to capture the most variance (helps focus on key changes in images, but could loose some interpretability)\nTexture analysis: Measures similarity between a pixel and its neighbors (useful for spotting urban areas or specific land features)\nImage fusion & pan-sharpening: Merges data from different sensors, often using high-resolution bands to sharpen lower-resolution images",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Sensing Data</span>"
    ]
  }
]