@article{cordeiroMappingVegetationLate2015,
  title = {Mapping Vegetation in a Late {{Quaternary}} Landform of the {{Amazonian}} Wetlands Using Object-Based Image Analysis and Decision Tree Classification},
  author = {Cordeiro, Carlos Leandro de Oliveira and {and Rossetti}, Dilce de F{\'a}tima},
  year = {2015},
  month = jul,
  journal = {International Journal of Remote Sensing},
  volume = {36},
  number = {13},
  pages = {3397--3422},
  publisher = {Taylor \& Francis},
  issn = {0143-1161},
  doi = {10.1080/01431161.2015.1060644},
  urldate = {2025-03-28},
  abstract = {Fan-shaped morphologies related to late Quaternary residual megafan depositional systems are common features over wide areas in northern Amazonia. These features were formed by ancient distributary drainage systems that are in great contrast to tributary drainage networks that typify the modern Amazon basin. The surfaces of the Amazonian megafans constitute vegetacional mosaic wetlands with different campinarana types. A fine-scale-resolution investigation is required to provide detailed classification maps for the various campinarana and surrounding forest types associated with the Amazonian megafans. This approach remains to be presented, despite its relevance for analysing the relationship between stages of plant succession and sedimentary dynamics associated with the evolution of megafans. In this work, we develop a methodology for classifying vegetation over a fan-shaped megafan palaeoform from a northern Amazonian wetland. The approach included object-based image analysis (OBIA) and data-mining (DM) techniques combining Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) images, land-cover fractions derived by the linear spectral mixing model, synthetic aperture radar (SAR) images, and the digital elevation model (DEM) acquired during the Shuttle Radar Topography Mission (SRTM). The DEM, vegetation fraction, and ASTER band 3 were the most useful parameters for defining the forest classes. The normalized difference vegetation index (NDVI), ASTER band 1, vegetation fraction, and the Advanced Land Observing Satellite (ALOS)/Phased Array type L-band Synthetic Aperture Radar (PALSAR) transmitting and receiving horizontal polarization (HH) and transmitting horizontal and receiving vertical polarization (HV) were all effective in distinguishing the wetland classes campinarana and Mauritia. Tests of statistical significance indicated the overall accuracies and kappa coefficients ({$\kappa$}) of 88\% and 0.86 for the final map, respectively. The allocation disagreement coefficient of 5\% and a quantity disagreement value of 7\% further attested the statistical significance of the classification results. Hence, in addition to water, exposed soil, and deforestation areas, OBIA and DM were successful for differentiating a large number of open (forest, wood, shrub, and grass campinaranas), forest (terra firme, v{\'a}rzea, igap{\'o}, and alluvial), as well as Mauritia wetland classes in the inner and outer areas of the studied megafan.}
}

@article{fallatahMappingInformalSettlement2019,
  title = {Mapping Informal Settlement Indicators Using Object-Oriented Analysis in the {{Middle East}}},
  author = {Fallatah, Ahmad and , Simon, Jones and , David, Mitchell and {and Kohli}, Divyani},
  year = {2019},
  month = jul,
  journal = {International Journal of Digital Earth},
  volume = {12},
  number = {7},
  pages = {802--824},
  publisher = {Taylor \& Francis},
  issn = {1753-8947},
  doi = {10.1080/17538947.2018.1485753},
  urldate = {2025-03-28},
  abstract = {Mapping informal settlements is crucial for resource and utility management and planning. In 2003, the UN-Habitat developed a process for mapping and monitoring urban inequality to support reporting against the sustainable development goals (SDGs). Informal settlement indicators are used as a framework to carry out image analysis, and include vegetation extent, lacunarity of housing structures / vacant land, road segment type and materials, texture measures of built-up areas, roofing extent of built-up areas and dwelling size. Object-based image analysis (OBIA) methods are recommended to identify informal settlements. This paper documents the application of OBIA to map informal settlements, drawing on the ontology of Kohli et al. (2012) and the indicators of Owen and Wong (2013) for a Middle Eastern city. Three informal settlements with different land use histories were selected to represent old and new informal settlements in the city of Jeddah, Saudi Arabia. Vegetation extent was the most successful indicator detected, with 100\% producer accuracy and over 84\% user accuracy, followed by the road network, with 84\% producer and user accuracies in older informal settlements and 73\% producer accuracy and 96\% user accuracy across all case studies. Lacunarity of housing structures / vacant land was detected well in informal settlements. The texture measure indicator was detected using GLCMEnt(R) with low producer accuracy across all case studies. The roofing extent of the built-up area is detected with better producer and user accuracies than texture measures. The dwellings size indicator generally failed to distinguish formal from informal settlements. Informal and formal were distinguished with an overall accuracy of 83\%. This research concludes that OBIA is a useful method to map informal settlement indicators in Middle Eastern cities. However, a generic ruleset for mapping informal settlements remains elusive, and each indicator requires significant localised `tuning'.},
  keywords = {high spatial resolution imagery,informal indicators,Informal settlement,Middle Eastern cities,object-based image analysis (OBIA),sustainable development goals},
  file = {C:\Users\FIORELLA\Zotero\storage\JDLI3FUZ\Fallatah et al. - 2019 - Mapping informal settlement indicators using object-oriented analysis in the Middle East.pdf}
}

@inproceedings{gram-hansenMappingInformalSettlements2019,
  title = {Mapping {{Informal Settlements}} in {{Developing Countries}} Using {{Machine Learning}} and {{Low Resolution Multi-spectral Data}}},
  booktitle = {Proceedings of the 2019 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {{Gram-Hansen}, Bradley J. and Helber, Patrick and Varatharajan, Indhu and Azam, Faiza and {Coca-Castro}, Alejandro and Kopackova, Veronika and Bilinski, Piotr},
  year = {2019},
  month = jan,
  series = {{{AIES}} '19},
  pages = {361--368},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3306618.3314253},
  urldate = {2025-03-28},
  abstract = {Informal settlements are home to the most socially and economically vulnerable people on the planet. In order to deliver effective economic and social aid, non-government organizations (NGOs), such as the United Nations Children's Fund (UNICEF), require detailed maps of the locations of informal settlements. However, data regarding informal and formal settlements is primarily unavailable and if available is often incomplete. This is due, in part, to the cost and complexity of gathering data on a large scale. To address these challenges, we, in this work, provide three contributions. 1) A brand new machine learning dataset purposely developed for informal settlement detection. 2) We show that it is possible to detect informal settlements using freely available low-resolution (LR) data, in contrast to previous studies that use very-high resolution{\textasciitilde}(VHR) satellite and aerial imagery, something that is cost-prohibitive for NGOs. 3) We demonstrate two effective classification schemes on our curated data set, one that is cost-efficient for NGOs and another that is cost-prohibitive for NGOs, but has additional utility. We integrate these schemes into a semi-automated pipeline that converts either a LR or VHR satellite image into a binary map that encodes the locations of informal settlements.},
  isbn = {978-1-4503-6324-2},
  file = {C:\Users\FIORELLA\Zotero\storage\PVLGLGN5\Gram-Hansen et al. - 2019 - Mapping Informal Settlements in Developing Countries using Machine Learning and Low Resolution Multi.pdf}
}

@article{howeComparingSentinel2Landsat2022a,
  title = {Comparing {{Sentinel-2}} and {{Landsat}} 8 for {{Burn Severity Mapping}} in {{Western North America}}},
  author = {Howe, Alexander A. and Parks, Sean A. and Harvey, Brian J. and Saberi, Saba J. and Lutz, James A. and Yocom, Larissa L.},
  year = {2022},
  month = jan,
  journal = {Remote Sensing},
  volume = {14},
  number = {20},
  pages = {5249},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs14205249},
  urldate = {2025-03-28},
  abstract = {Accurate assessment of burn severity is a critical need for an improved understanding of fire behavior and ecology and effective post-fire management. Although NASA Landsat satellites have a long history of use for remotely sensed mapping of burn severity, the recently launched (2015 and 2017) European Space Agency Sentinel-2 satellite constellation offers increased temporal and spatial resolution with global coverage, combined with free data access. Evaluations of burn severity derived from Landsat and Sentinel generally show comparable results, but these studies only assessed a small number of fires with limited field data. We used 912 ground calibration plots from 26 fires that burned between 2016 and 2019 in western North America to compare Sentinel- and Landsat-derived burn severity estimates with the field-based composite burn index. We mapped burn severity using two methods; the well-established paired scene approach, in which a single pre- and post-fire scene are selected for each fire, and also a mean image compositing approach that automatically integrates multiple scenes using the cloud-based remote sensing platform Google Earth Engine. We found that Sentinel generally performed as well or better than Landsat for four spectral indices of burn severity, particularly when using atmospherically corrected Sentinel imagery. Additionally, we tested the effects of mapping burn severity at Sentinel's finer spatial resolution (10 m) on estimates of the spatial complexity of stand-replacing fire, resulting in a 5\% average reduction per-fire in area mapped as high-severity patch interiors (24,273 ha total) compared to mapping at the resolution of Landsat (30 m). These findings suggest Sentinel may improve ecological discrimination of fine-scale fire effects, but also warrant caution when comparing estimates of burn severity spatial patterns derived at different resolutions. Overall, these results indicate that burn severity mapping will benefit substantially from the integration of Sentinel imagery through increased imagery availability, and that Sentinel's higher spatial resolution improves opportunities for examining finer-scale fire effects across ecosystems.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {atmospheric correction,composite burn index,fire severity,Google Earth Engine,image compositing,imagery resolution,spatial scale,spectral indices,temperate forests,wildfire},
  file = {C:\Users\FIORELLA\Zotero\storage\5X3EX8I4\Howe et al. - 2022 - Comparing Sentinel-2 and Landsat 8 for Burn Severity Mapping in Western North America.pdf}
}

@article{leeDetectingIndustrialOil2016,
  title = {Detecting Industrial Oil Palm Plantations on {{Landsat}} Images with {{Google Earth Engine}}},
  author = {Lee, Janice Ser Huay and Wich, Serge and Widayati, Atiek and Koh, Lian Pin},
  year = {2016},
  month = oct,
  journal = {Remote Sensing Applications: Society and Environment},
  volume = {4},
  pages = {219--224},
  issn = {2352-9385},
  doi = {10.1016/j.rsase.2016.11.003},
  urldate = {2025-03-28},
  abstract = {Oil palm plantations are rapidly expanding in the tropics, which leads to deforestation and other associated damages to biodiversity and ecosystem services. Forest researchers and practitioners in developing nations are in need of a low-cost, accessible and user-friendly tool for detecting the establishment of industrial oil palm plantations. Google Earth Engine (GEE) is a cloud computing platform which hosts publicly available satellite images and allows for land cover classification using inbuilt algorithms. These algorithms conduct pixel-based classification via supervised learning. We demonstrate the use of GEE for the detection of industrial oil palm plantations in Tripa, Aceh, Indonesia. We performed land cover classification using different spectral bands (RGB, NIR, SWIR, TIR, all bands) from our Landsat 8 image to distinguish the following land cover classes: immature oil palm, mature oil palm, non-forest non-oil palm, forest, water, and clouds. The overall accuracy and Kappa coefficient were the highest using all bands for land cover classification, followed by RGB, SWIR, TIR, and NIR. Classification and Regression Trees (CART) and Random Forests (RFT) algorithms produced classified land cover maps which had higher overall accuracies and Kappa coefficients than the Minimum Distance (MD) algorithm. Object-based classification and using a combination of radar- and optic-based imagery are some ways in which oil palm detection can be improved within GEE. Despite its limitations, GEE does have the potential to be developed further into an accessible and low-cost tool for independent bodies to detect and monitor the expansion of oil palm plantations in the tropics.},
  keywords = {Agricultural expansion,Land cover classification,Land use change,Tropics},
  file = {C:\Users\FIORELLA\Zotero\storage\MKQLK4W9\Lee et al. - 2016 - Detecting industrial oil palm plantations on Landsat images with Google Earth Engine.pdf}
}

@article{luRolesTexturalImages2014,
  title = {The Roles of Textural Images in Improving Land-Cover Classification in the {{Brazilian Amazon}}},
  author = {Lu, Dengsheng and , Guiying, Li and , Emilio, Moran and , Luciano, Dutra and {and Batistella}, Mateus},
  year = {2014},
  month = dec,
  journal = {International Journal of Remote Sensing},
  volume = {35},
  number = {24},
  pages = {8188--8207},
  publisher = {Taylor \& Francis},
  issn = {0143-1161},
  doi = {10.1080/01431161.2014.980920},
  urldate = {2025-03-28},
  abstract = {Texture has long been recognized as valuable in improving land-cover classification, but how data from different sensors with varying spatial resolutions affect the selection of textural images is poorly understood. This research examines textural images from the Landsat Thematic Mapper (TM), ALOS (Advanced Land Observing Satellite) PALSAR (Phased Array type L-band Synthetic Aperture Radar), the SPOT (Satellite Pour l'Observation de la Terre) high-resolution geometric (HRG) instrument, and the QuickBird satellite, which have pixel sizes of 30, 12.5, 10/5, and 0.6~m, respectively, for land-cover classification in the Brazilian Amazon. GLCM (grey-level co-occurrence matrix)-based texture measures with various sizes of moving windows are used to extract textural images from the aforementioned sensor data. An index based on standard deviations and correlation coefficients is used to identify the best texture combination following separability analysis of land-cover types based on training sample plots. A maximum likelihood classifier is used to conduct the land-cover classification, and the results are evaluated using field survey data. This research shows the importance of textural images in improving land-cover classification, and the importance becomes more significant as the pixel size improved. It is also shown that texture is especially important in the case of the ALOS PALSAR and QuickBird data. Overall, textural images have less capability in distinguishing land-cover types than spectral signatures, especially for Landsat TM imagery, but incorporation of textures into radiometric data is valuable for improving land-cover classification. The classification accuracy can be improved by 5.2--13.4\% as the pixel size changes from 30 to 0.6~m.},
  file = {C:\Users\FIORELLA\Zotero\storage\LKYXGIPW\Lu et al. - 2014 - The roles of textural images in improving land-cover classification in the Brazilian Amazon.pdf}
}

@article{masonDetectionFloodedUrban2014,
  title = {Detection of Flooded Urban Areas in High Resolution {{Synthetic Aperture Radar}} Images Using Double Scattering},
  author = {Mason, D. C. and Giustarini, L. and {Garcia-Pintado}, J. and Cloke, H. L.},
  year = {2014},
  month = may,
  journal = {International Journal of Applied Earth Observation and Geoinformation},
  volume = {28},
  pages = {150--159},
  issn = {1569-8432},
  doi = {10.1016/j.jag.2013.12.002},
  urldate = {2025-03-28},
  abstract = {Flooding is a particular hazard in urban areas worldwide due to the increased risks to life and property in these regions. Synthetic Aperture Radar (SAR) sensors are often used to image flooding because of their all-weather day--night capability, and now possess sufficient resolution to image urban flooding. The flood extents extracted from the images may be used for flood relief management and improved urban flood inundation modelling. A difficulty with using SAR for urban flood detection is that, due to its side-looking nature, substantial areas of urban ground surface may not be visible to the SAR due to radar layover and shadow caused by buildings and taller vegetation. This paper investigates whether urban flooding can be detected in layover regions (where flooding may not normally be apparent) using double scattering between the (possibly flooded) ground surface and the walls of adjacent buildings. The method estimates double scattering strengths using a SAR image in conjunction with a high resolution LiDAR (Light Detection and Ranging) height map of the urban area. A SAR simulator is applied to the LiDAR data to generate maps of layover and shadow, and estimate the positions of double scattering curves in the SAR image. Observations of double scattering strengths were compared to the predictions from an electromagnetic scattering model, for both the case of a single image containing flooding, and a change detection case in which the flooded image was compared to an un-flooded image of the same area acquired with the same radar parameters. The method proved successful in detecting double scattering due to flooding in the single-image case, for which flooded double scattering curves were detected with 100\% classification accuracy (albeit using a small sample set) and un-flooded curves with 91\% classification accuracy. The same measures of success were achieved using change detection between flooded and un-flooded images. Depending on the particular flooding situation, the method could lead to improved detection of flooding in urban areas.},
  keywords = {Double scattering,Flood detection,Synthetic Aperture Radar,Urban area},
  file = {C:\Users\FIORELLA\Zotero\storage\XF5BJZVU\S0303243413001700.html}
}

@incollection{PDFRemoteSensing,
  title = {({{PDF}}) ``{{Remote Sensing}} of {{Wetlands}}: {{Applications}} and {{Advances}}''},
  shorttitle = {({{PDF}}) ``{{Remote Sensing}} of {{Wetlands}}},
  booktitle = {{{ResearchGate}}},
  urldate = {2025-03-28},
  abstract = {PDF {\textbar} On May 1, 2015, B. Brisco published ``Remote Sensing of Wetlands: Applications and Advances'' {\textbar} Find, read and cite all the research you need on ResearchGate},
  langid = {english},
  file = {C:\Users\FIORELLA\Zotero\storage\KKXNHMIX\271765042_Remote_Sensing_of_Wetlands_Applications_and_Advances.html}
}

@article{siokMultiSensorFusionSimulation2020,
  title = {Multi-{{Sensor Fusion}}: {{A Simulation Approach}} to {{Pansharpening Aerial}} and {{Satellite Images}}},
  shorttitle = {Multi-{{Sensor Fusion}}},
  author = {Siok, Katarzyna and Ewiak, Ireneusz and Jenerowicz, Agnieszka},
  year = {2020},
  month = jan,
  journal = {Sensors},
  volume = {20},
  number = {24},
  pages = {7100},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s20247100},
  urldate = {2025-03-28},
  abstract = {The growing demand for high-quality imaging data and the current technological limitations of imaging sensors require the development of techniques that combine data from different platforms in order to obtain comprehensive products for detailed studies of the environment. To meet the needs of modern remote sensing, the authors present an innovative methodology of combining multispectral aerial and satellite imagery. The methodology is based on the simulation of a new spectral band with a high spatial resolution which, when used in the pansharpening process, yields an enhanced image with a higher spectral quality compared to the original panchromatic band. This is important because spectral quality determines the further processing of the image, including segmentation and classification. The article presents a methodology of simulating new high-spatial-resolution images taking into account the spectral characteristics of the photographed types of land cover. The article focuses on natural objects such as forests, meadows, or bare soils. Aerial panchromatic and multispectral images acquired with a digital mapping camera (DMC) II 230 and satellite multispectral images acquired with the S2A sensor of the Sentinel-2 satellite were used in the study. Cloudless data with a minimal time shift were obtained. Spectral quality analysis of the generated enhanced images was performed using a method known as ``consistency'' or ``Wald's protocol first property''. The resulting spectral quality values clearly indicate less spectral distortion of the images enhanced by the new methodology compared to using a traditional approach to the pansharpening process.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {aerial images,multi-sensor fusion,pansharpening,satellite imagery,simulation,spectral quality},
  file = {C:\Users\FIORELLA\Zotero\storage\Z8GFGPEF\Siok et al. - 2020 - Multi-Sensor Fusion A Simulation Approach to Pansharpening Aerial and Satellite Images.pdf}
}
